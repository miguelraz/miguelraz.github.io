<?xml version="1.0" encoding="UTF-8"?>

<rss version="2.0"
      xmlns:content="http://purl.org/rss/1.0/modules/content/"
      xmlns:dc="http://purl.org/dc/elements/1.1/"
      xmlns:media="http://search.yahoo.com/mrss/"
      xmlns:atom="http://www.w3.org/2005/Atom"
      xmlns:georss="http://www.georss.org/georss">

      <channel>
        <title><![CDATA[PathToPerformance]]></title>
        <link>https://miguelraz.github.io</link>
        <description><![CDATA[A virtual diary for progress on all fronts by Miguel Raz GuzmÃ¡n Macedo]]></description>
        <generator>Franklin.jl -- https://github.com/tlienart/Franklin.jl</generator>
        <atom:link
            href="https://miguelraz.github.io/feed.xml"
            rel="self"
            type="application/rss+xml" />


<item>
    <title><![CDATA[GSoC in LLVM 2024]]></title>
    <link>https://miguelraz.github.io/blog/gsoc2024/index.html</link>
    <guid>9</guid>
    <description><![CDATA[GSoC in LLVM 2024]]></description>    
    
    <content:encoded><![CDATA[<h1 id="im_trying_to_get_a_gsoc_2024_in_llvm">I&#39;m trying to get a GSoC 2024 in LLVM</h1>
<p>and I will be documenting my work with this ongoing blogpost in reverse chronological order.</p>
<hr />
<p>If you want to see more posts like this, consider chucking a buck or two on my <a href="https://github.com/miguelraz">GitHub sponsors</a>, or, you know, hire me as a grad student.</p>
<hr />
<h2 id="23022024">23/02/2024</h2>
<p>Only added stubs for where <code>ISD::&#91;US&#93;CMP</code> will go in the <code>LegalizerDAG.cpp</code>. Some code is better than no code&#33;</p>
<h2 id="22022024">22/02/2024 </h2>
<p>Back from exams. I let my mentors know I wouldn&#39;t be around for a few and would come back later.</p>
<p>Omg Nori taught me how to use vim marks &#40;even within VSCode&#41;. <code>ma</code> will set a mark <code>a</code> and <code>&#39;a</code> lets you jump back to it. If you set an uppercase one, it&#39;s GLOBAL and you can jump between files&#33;</p>
<h2 id="19022024">19/02/2024</h2>
<p>Got feedback for the proposal. Seems people like not reading ChatGPT scripts, whodathunkit. Aggregated suggestions and sent it off. Should update if I get more updates.</p>
<p>Also, rebased the next step of the PR, which is merging into the <a href="https://github.com/llvm/llvm-project/pull/85822">SelectionDAG</a></p>
<p>Alright, pushed some code that probably fails on everything but can&#39;t get more brainpower on learning the casting RTTI APIs today.</p>
<h2 id="18022024">18/02/2024 </h2>
<p>IT GOT MERGED&#33;</p>
<p>I wrote up the draft proposal, and sent it for feedback from the mentors.</p>
<p>Tomorrow I&#39;ll try to get started on the next steps of the proposal and send a dummy PR to get to the good stuff.</p>
<h2 id="17022024">17/02/2024 </h2>
<p>Actually just rested yesterday. &#39;Twas good. Today I&#39;ll do some  light reading.</p>
<ul>
<li><p><code>isa&lt;&gt;, cast&lt;&gt;, dyn_cast&lt;&gt;</code> templates</p>
<ul>
<li><p><code>isa&lt;&gt;</code> returns <code>true/false</code> if it&#39;s an instance of the specified class </p>
</li>
<li><p><code>cast&lt;&gt;</code> is a &quot;checked cast&quot;</p>
</li>
<li><p><code>dyn_cast&lt;&gt;</code> usually used in <code>if &#40;auto *AI &#61; dyn_cast&lt;AllocationInst&gt;&#40;Val&#41;&#41; &#123;</code></p>
</li>
</ul>
</li>
<li><p><code>STringRef</code> and <code>Twine</code> - <code>Value</code> class and <code>StringMap</code> must be generic over null chars, can&#39;t take a <code>const char*</code></p>
</li>
<li><p>Error handling: abort early, use <code>assert&#40;cond &amp;&amp; &quot;you done goofed&quot;&#41;;</code></p>
</li>
</ul>
<pre><code class="language-julia">enum &#123; Foo, Bar, Baz &#125; X &#61; foo&#40;&#41;;switch &#40;X&#41; &#123;
  case Foo: /* Handle Foo */; break;
  case Bar: /* Handle Bar */; break;
  default:
    llvm_unreachable&#40;&quot;X should be Foo or Bar here&quot;&#41;;
&#125;</code></pre>
<ul>
<li><p>use LLVM_DEBUG and <a href="https://llvm.org/docs/ProgrammersManual.html#fine-grained-debug-info-with-debug-type-and-the-debug-only-option">friends</a></p>
</li>
</ul>
<pre><code class="language-julia">LLVM_DEBUG&#40;dbgs&#40;&#41; &lt;&lt; &quot;I am here&#33;\n&quot;&#41;;</code></pre>
<p>and then </p>
<pre><code class="language-julia">&#36; opt &lt; a.bc &gt; /dev/null -mypass
&lt;no output&gt;
&#36; opt &lt; a.bc &gt; /dev/null -mypass -debug
I am here&#33;</code></pre>
<ul>
<li><p>Use the <a href="https://llvm.org/docs/ProgrammersManual.html#the-statistic-class-stats-option">Statistic</a> class&#33;</p>
</li>
<li><p>stopped at picking the right data structure.</p>
</li>
</ul>
<h2 id="16022024">16/02/2024 </h2>
<p>Start: read LLVM Programmer&#39;s Manual, then start with some local changes to the SelectionDAG.</p>
<h2 id="15022024">15/02/2024</h2>
<p>Derp, I kept getting &quot;undefined intrinsics&quot; errors when running FileCheck like </p>
<pre><code class="language-julia">&gt; ../../../build/bin/opt -S -passes&#61;verify 2&gt;&amp;1 intrinsic-cmp.ll | FileCheck intrinsic-cmp.ll</code></pre>
<p>... because I had to rebuild LLVM and have the new <code>opt</code> pick it up. Once that happened, even the new <code>llvm-lit</code> passed :D</p>
<p>I also had to remove the <code>CHECK-LABEL</code>, still not sure why. Lemme read that for a bit.</p>
<p>Also, I should update <code>mold</code> - it failed with an unknown <code>--long-plt</code> option.</p>
<p>Here&#39;s my LLVM build instruction: </p>
<pre><code class="language-julia">&gt; cmake -S . -B build -G Ninja -DLLVM_TARGETS_TO_BUILD&#61;X86 -DBUILD_SHARED_LIBS&#61;ON -DCMAKE_BUILD_TYPE&#61;Debug -DLLVM_OPTIMIZED_TABLEGEN&#61;ON -DLLVM_USE_NEWPM&#61;ON -DLLVM_USE_SPLIT_DWARF&#61;ON -DLLVM_PARALLEL_LINKER_JOBS&#61;10 -DLLVM_PARALLEL_COMPILE_JOBS&#61;10
&gt; mold -run ninja -C .</code></pre>
<p>Windows builders take freakin&#39; forever to run.</p>
<ul>
<li><p>Coding Standards </p>
<ul>
<li><p>prefer <code>llvm::DenseMap</code> over <code>std::unordered_map</code> and similar. No std IO plz.</p>
</li>
<li><p>comments - write what does is trying to do and why, not <em>how</em></p>
</li>
<li><p>spaces not tabs</p>
</li>
<li><p>prefer C&#43;&#43; style casts like <code>auto DestVecLen &#61; cast&lt;VectorType&gt;&#40;DestTy&#41;-&gt;getElementCount&#40;&#41;;</code> for getting the Vector length</p>
</li>
<li><p>beware <code>auto</code> copies:</p>
</li>
</ul>
</li>
</ul>
<pre><code class="language-julia">// Typically there&#39;s no reason to copy.
for &#40;const auto &amp;Val : Container&#41; observe&#40;Val&#41;;
for &#40;auto &amp;Val : Container&#41; Val.change&#40;&#41;;// Remove the reference if you really want a new copy.
for &#40;auto Val : Container&#41; &#123; Val.change&#40;&#41;; saveSomewhere&#40;Val&#41;; &#125;// Copy pointers, but make it clear that they&#39;re pointers.
for &#40;const auto *Ptr : Container&#41; observe&#40;*Ptr&#41;;
for &#40;auto *Ptr : Container&#41; Ptr-&gt;change&#40;&#41;;</code></pre>
<p>* use early returns, specially in loops:</p>
<pre><code class="language-julia">// not this 
for &#40;Instruction &amp;I : BB&#41; &#123;
  if &#40;auto *BO &#61; dyn_cast&lt;BinaryOperator&gt;&#40;&amp;I&#41;&#41; &#123;
    Value *LHS &#61; BO-&gt;getOperand&#40;0&#41;;
    Value *RHS &#61; BO-&gt;getOperand&#40;1&#41;;
    if &#40;LHS &#33;&#61; RHS&#41; &#123;
      ...
    &#125;
  &#125;
&#125;
// prefer this 
for &#40;Instruction &amp;I : BB&#41; &#123;
  auto *BO &#61; dyn_cast&lt;BinaryOperator&gt;&#40;&amp;I&#41;;
  if &#40;&#33;BO&#41; continue;  Value *LHS &#61; BO-&gt;getOperand&#40;0&#41;;
  Value *RHS &#61; BO-&gt;getOperand&#40;1&#41;;
  if &#40;LHS &#61;&#61; RHS&#41; continue;  ...
&#125;</code></pre>
<p>* other good tips for no *else* after a *return* 
* turn predicate loops into functions 
* assert liberally&#33; you may find other people&#39;s bugs&#33; <code>assert&#40;Ty-&gt;isPointerType&#40;&#41; &amp;&amp; &quot;Can&#39;t allocate a non-pointer type&#33;&quot;&#41;;</code>
* consider <code>llvm::unreachable&#40;&quot;invalid radix for integer literal&quot;&#41;</code>
* never <code>using namespace std</code>
* don&#39;t evaluate <code>end&#40;&#41;</code> every time through a loop&#33;</p>
<pre><code class="language-julia">// not this
BasicBlock *BB &#61; ...
for &#40;auto I &#61; BB-&gt;begin&#40;&#41;; I &#33;&#61; BB-&gt;end&#40;&#41;; &#43;&#43;I&#41;
  ... use I ...// prefer this 
BasicBlock *BB &#61; ...
for &#40;auto I &#61; BB-&gt;begin&#40;&#41;, E &#61; BB-&gt;end&#40;&#41;; I &#33;&#61; E; &#43;&#43;I&#41;
  ... use I ...</code></pre>
<p>* lol <code>#include &lt;iostream&gt;</code> is forbidden, as well as <code>std::endl</code>
* prefer preincrement &#40;&#43;&#43;x&#41;
* anonymous namespaces allow more aggressive optimizations&#33; make them small and only use them for class declarations
* omit braces on short if&#39;s -_-
* read &quot;Effective C&#43;&#43;&quot; by Scott Meyers or &quot;Large Scale C&#43;&#43; Software Design&quot; by John Lakos. later.</p>
<p>BIG ALERT&#33; We&#39;re passing all tests and Nikita says &quot;LGTM&#33;&quot; Huzzahhh&#33;</p>
<p>I finished reading the Coding Standards and will now read the LLVM Programmer&#39;s Manual.</p>
<p>Afternoon: only 1 reviewer missing approval&#33;</p>
<h2 id="14022024">14/02/2024 </h2>
<p>It&#39;s close to finishingggggggggg</p>
<p>Nikita mentioned the <a href="https://llvm.org/docs/CodingStandards.html#name-types-functions-variables-and-enumerators-properly">CodingStandars</a>, I&#39;ll give that a read in a bit.</p>
<p>In <code>FileCheck</code> unit tests, it&#39;s just 2 spaces, not tabs or 4 spaces.</p>
<p>Dhruv recommends using <code>git clang-format</code> or <code>Format Modified Lines</code> in VSCode.</p>
<p>I only have to make <code>FileCheck</code> pass now and Nikita says it should be good&#33;</p>
<h2 id="13022024">13/02/2024 </h2>
<p>OK, I just saw that both Nikita Popov and Dhruv Chawla are listed as mentors for the project. Should try and reach out before the application period begins.</p>
<p>Nikita commented that there&#39;s two good places to look into &#40;which I should do meanwhile&#41;:</p>
<ul>
<li><p>The <a href="https://llvm.org/docs/CodeGenerator.html#instruction-selection-section">Selection DAG part of the manual</a></p>
</li>
<li><p>The good first issues on the github tracker, which probably are good to look into.</p>
</li>
</ul>
<h3 id="notes_on_the_selectiondag">Notes on the SelectionDAG </h3>
<ul>
<li><p>GlobalISel and SelectionDAG both translated LLVM code to target specific machine instructions.</p>
</li>
<li><p>In theory Intrinsics.td should handle it all but some parts need custo C&#43;&#43; code.</p>
</li>
<li><p>SDAGs represent Machine Value Types and DataFlow types. Dataflow types provide ordering.</p>
</li>
<li><p>Legal vs illegal DAG: only use supported ops on supported types </p>
</li>
<li><p>SDAG phases: build, optimize, legalizeTypes, optimize, legalize, select instructions, scheduling       * common to use <code>-debug-only&#61;isel/-dump</code> and <code>-filter-print-funcs&#61;&lt;function-name&gt;</code></p>
<ul>
<li><p>several flags can print SDAG after each pass </p>
</li>
</ul>
</li>
<li><p>OK, effective sign extension elimination seems to be highly non-trivial optimizations</p>
</li>
<li><p>Oohhhh TableGen representing stuff as a DAG lets you build the SelectionDAG on top of it&#33;</p>
</li>
</ul>
<p>After a few hours of noodling with PR reviews, it&#39;s clear I gotta jump on a next one/help PR review some other people. Maybe it&#39;s not great to go full mercenary on every <code>good-first-issue</code> and try and help others along the way.</p>
<p><code>ParticleSwarmOptimization</code> was kind enough in the <code>LLVM/beginners</code> Discord chat to point out that I should have a full build of LLVM and then run <code>llvm-lit</code> from there on a unit test. Sure enough, that let me do <code>gh pr checkout 84903</code> and then <code>LIT llvm/test/CodeGen/AArch64/hadd-combine.ll</code> to check that a unit test properly ran. Now I can help verify my own and other people&#39;s PRs&#33; yay&#33;</p>
<p>That seems like enough for today, I&#39;ll hunt for some good issues tomorrow.</p>
<h2 id="12022024">12/02/2024 </h2>
<p>Did a bunch of very quick fixes and got some neat feedback.</p>
<h2 id="11022024">11/02/2024 </h2>
<p>Ohhhhhh neat&#33; Got some really fast feedback this time around on stray newlines and a couple fixes on the PR.  Things are moving faster and faster&#33; I <em>think</em> I&#39;m only missing adding some <code>FileCheck</code> tests for the  invariants under the <code>Verifier.cpp</code> stuff that isn&#39;t handled by <code>Intrinsics.td</code> but that sounds about it&#33;</p>
<p><a href="https://llvm.org/docs/CommandGuide/FileCheck.html">FileCheck</a> reading I&#39;ll do for a bit.</p>
<p>Note: If you are going to check multiple things in a single file, use a <code>CHECK-LABEL</code> to avoid spurious matches.</p>
<p>Sometimes, a <code>CHECK-NEXT</code> is useful as the last unit test. </p>
<p>Learned the LLVMIR verbose call syntax goes &#40;gotta include types in call site&#41;.</p>
<p>That should do it for today, see y&#39;all tomorrow.</p>
<h2 id="10022024">10/02/2024 </h2>
<p>Plan for today: Read the IR Verifier, add code to it if needed, then work on adding to SDAG node.</p>
<p>IR Verifier code: It&#39;s under <code>llvm/IR/Verifier.h</code> and <code>llvm/IR/Verifier.cpp</code>.</p>
<p>Ok, read the code for a bit. What I&#39;m interested in in <code>Verifier.cpp</code> is the huge switch statement towards the end of the file where the verification of intrinsics happens.</p>
<p>Oh neat, learned a lot of places that probably need modification via searching <code>case Intrinsic::</code> in the llvm folder.</p>
<p>Neat&#33; <code>VectorUtils.cpp</code> looks like where we add SIMD :D</p>
<p>There is also a <code>SelectionDAGBuilder.cpp</code> that seems like I should update stuff there.</p>
<p>Ah, seems the SDAG needs the ID node to be added to the ISDOpcodes first, like <code>ISD::SCMP</code> and such.</p>
<p><a href="https://llvm.org/docs/LangRef.html#intrinsic-functions">Intrinsic Function</a>: start with <code>llvm.</code> prefix. Must always be external functions. If any are added, must be documented in LangRef. Have naming convention on type name return.</p>
<p>In <code>TargetLowering.h</code>:</p>
<pre><code class="language-julia">/// This class defines information used to lower LLVM code to legal SelectionDAG
/// operators that the target instruction selector can accept natively.
///
/// This class also defines callbacks that targets must implement to lower
/// target-specific constructs to SelectionDAG operators.
class TargetLowering : public TargetLoweringBase &#123;</code></pre>
<p>Updated the PR to not include a dirty file from the <code>ValueTracking.cpp</code> unit tests.</p>
<p>Sweet, rebased the <code>spaceship-intrinsic</code> branch changes into a new one.</p>
<p>Now I can go for </p>
<pre><code class="language-julia">lib/CodeGen/SelectionDAG/SelectionDAG.cpp:Add code to print the node to getOperationName. If your new node can be
evaluated at compile time when given constant arguments &#40;such as an add of a constant with another constant&#41;, find the getNode method that takes the appropriate number of arguments, and add a case for your node to the switch statement that performs constant folding for nodes that take the same number of arguments as your new node.</code></pre>
<p>Which gives on Line 6629 of <code>SelectionDAG.cpp</code></p>
<pre><code class="language-julia">SDValue SelectionDAG::getNode&#40;unsigned Opcode, const SDLoc &amp;DL, EVT VT,
                              SDValue N1, SDValue N2, const SDNodeFlags Flags&#41; &#123;</code></pre>
<p>where I can add an <code>case ISD::UCMP</code>/<code>case ISD::SCMP</code>. </p>
<p>Oh wow, having VSCode let me just hover over a type and give me info is amazing.</p>
<p>Alright, did some good work today I think.</p>
<hr />
<p>Got some feedback on typo fixes from other people and some concrete directions from Nikita:</p>
<pre><code class="language-julia">def int_scmp : DefaultAttrsIntrinsic&lt;
    &#91;llvm_anyint_ty&#93;, &#91;llvm_anyint_ty, LLVMMatchType&lt;1&gt;&#93;,
    &#91;IntrNoMem, IntrSpeculatable, IntrWillReturn&#93;&gt;;</code></pre>
<p>for the <code>Intrinsics.td</code> so that we can have a &quot;result type overload over a fixed type&quot; and then </p>
<blockquote>
<p>and then add a check in Verifier.cpp that a&#41; the return type and the first argument type have the same number of elements &#40;if they are vectors&#41; and b&#41; the return scalar type has width at least 2.</p>
</blockquote>
<p>So I&#39;ve pushed a commit already to have the <code>Intrinsics.td</code> that way and I will now add a case to the <code>Verifier.cpp</code> in the <code>void Verifier::visitIntrinsicCall&#40;Intrinsic::ID ID, CallBase &amp;Call&#41; &#123;</code> to add </p>
<p>&#40;Many hours later&#41; Put in a good first effort into the <code>Verifier.cpp</code> cases for <code>Intrinsic::scmp/ucmp</code>. It&#39;s probably a bit boneheaded but I&#39;ve been getting really good and fast feedback on the PRs, so I feel encouraged to keep the hot streak going.</p>
<h2 id="09022024">09/02/2024</h2>
<p>Lost the renaming battle to standard practices. Can&#39;t complain. Updated the PR to reflect that.</p>
<p>Now, reading the <a href="https://github.com/llvm/llvm-project/blob/release/17.x/llvm/lib/Transforms/Scalar/DCE.cpp">DCE</a> pass code.</p>
<p>Ok, Andrzej WarzyÅski did <a href="https://www.youtube.com/watch?v&#61;ar7cJl2aBuU">an incredibly useful tutorial</a> for <code>llvm-tutor</code>.</p>
<p>I&#39;ll try writing the Transformation pass, since it&#39;s closes to what I need.</p>
<p>Notes:     * <code>LLVM_DEBUG</code> is super useful. </p>
<pre><code class="language-julia">#include &quot;llvm/ADT/Statistic.h&quot;
#include &quot;llvm/Support/Debug.h&quot;#define DEBUG_TYPE &quot;mba-add&quot;
STATISIC&#40;SubstCount, &quot;The # of substituted instructions&quot;</code></pre>
<p>and then you can do:</p>
<pre><code class="language-julia">LLVM_DEBUG&#40;dbgs&#40;&#41; &lt;&lt; *BinOp &lt;&lt; &quot; -&gt; &quot; &lt;&lt; *NewInst &lt;&lt; &quot;\n&quot;;
    // or , with Statistic and &#96;-stat&#96; on the &#96;opt&#96; CLI and debug build
    &#43;&#43;SubstCount;</code></pre>
<ul>
<li><p>Analysis inherits from <code>AnalysisInfoMixin</code></p>
</li>
<li><p>Very common pattern:</p>
</li>
</ul>
<pre><code class="language-julia">for &#40;auto &amp;Func : M&#41; &#123;
    for &#40;auto &amp;BB : Func&#41; &#123;
        for &#40;auto &amp;Ins : BB&#41; &#123;
            ...</code></pre>
<ul>
<li><p>You call <code>PreservedAnalysis.abandon&#40;&#41;</code> when you wanna bail on a logic.</p>
</li>
<li><p><code>FileCheck</code> is a pattern matching tool that comes with LLVM. Can check emitted assembly output for test correctness.</p>
</li>
<li><p>Rely on CMake&#39;s <code>find_package</code> and add sanity-checks to your scripts&#33;</p>
</li>
<li><p>LLDB is your friend </p>
</li>
</ul>
<pre><code class="language-julia">lldb -- &#36;LLVM_DIR/bin/opt -load-pass-plugin lib/libMyPass.so -passes&#61;my-pass -S dummy.ll
&#40;lldb&#41; b MyPass::run 
&#40;lldb&#41; r</code></pre>
<p>Finally: started a branch called <code>scmp-and-ucmp</code> and I&#39;ll start trying out changes there whilst people make up their minds.</p>
<h2 id="8022024">8/02/2024 </h2>
<p>Jyn strikes again and sometimes you can just do <code>make</code> after <code>cmake</code> because some stuff is optional.</p>
<p>Otherwise, install:</p>
<pre><code class="language-julia">sudo apt install libzstd-dev libcurl4-openssl-dev libedit-dev</code></pre>
<p>to get rolling.</p>
<p>Once you do </p>
<pre><code class="language-julia"># Run the pass
&#36;LLVM_DIR/bin/opt -load-pass-plugin ./libHelloWorld.&#123;so|dylib&#125; -passes&#61;hello-world -disable-output input_for_hello.ll
# Expected output
&#40;llvm-tutor&#41; Hello from: foo
&#40;llvm-tutor&#41;   number of arguments: 1
&#40;llvm-tutor&#41; Hello from: bar
&#40;llvm-tutor&#41;   number of arguments: 2
&#40;llvm-tutor&#41; Hello from: fez
&#40;llvm-tutor&#41;   number of arguments: 3
&#40;llvm-tutor&#41; Hello from: main
&#40;llvm-tutor&#41;   number of arguments: 2</code></pre>
<p>using <code>-disable-output</code> means no bitcode gets produced.</p>
<p>Passes come in 3 flavors, mostly: Analysis, Transformations and CFG manipulations.</p>
<p>Note that <code>clang</code> adds the <code>optnone</code> function attribute if 1&#41; no opt level is specified or <code>-O0</code> is specified. </p>
<p>Ah, forgot to run the <code>cmake .. -&gt; mold -run make -j</code> and had some passes missing. Derp.</p>
<p>Minutes lost to cmake bullshit: 60.</p>
<p>Oh sweet&#33; I just learned that I can write an injection pass that will give me a new binary and it will print out cool analysis info.</p>
<p>Also, if I get an instrumented binary I can just use <code>lli</code> to interpret the <code>.ll</code> file directly.</p>
<p>You can also build a static binary that will run that analysis for you&#33; </p>
<p>Ran a bunch of passes with <code>opt</code> and friends. Transformation passes will normally inherit from <code>PassInfoMixin</code>.</p>
<p>Analysis Passes will inherit from <code>AnalysisInfoMixin</code>.</p>
<p>Ok, cool I an outdated example in llvm-tutor <a href="https://github.com/banach-space/llvm-tutor/pull/111">in the examples</a> and sent a PR for it.</p>
<p>Tomorrow I shall dive into those optimization passes at the end and hopefully run some good <code>lit</code> tests.</p>
<h2 id="7022024">7/02/2024 </h2>
<p>Alright, did some good catchup on the semester and pushed the <a href="https://discourse.llvm.org/t/rfc-add-3-way-comparison-intrinsics/76685/7?u&#61;miguelraz">PR forward a bit</a>.</p>
<p>I also had an awesome &quot;uniwtting tourist&quot; genius moment by pointing out the return type could be different than what Nikita had thought of.</p>
<p>Today I setup my environment with</p>
<pre><code class="language-julia">wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -
sudo apt-add-repository &quot;deb http://apt.llvm.org/jammy/ llvm-toolchain-jammy-17 main&quot;
sudo apt-get update
sudo apt-get install -y llvm-17 llvm-17-dev llvm-17-tools clang-17</code></pre>
<p>so now I can run <code>opt</code> shenanigans without awkward path invocations.</p>
<h2 id="2022024">2/02/2024 </h2>
<p>I&#39;m waiting for others to chime in on my latest fix so I will be reading on how to add <a href="https://llvm.org/docs/TestingGuide.html">unit tests</a>.</p>
<p>Cool, that took like 25 minutes and I pushed a commit into the unit test generation framework.</p>
<p>Took me a bit but tried adding using <code>llvm-lit</code> and couldn&#39;t get the <code>Examples</code> folder to run, so I posted a question in the #beginners channel about it.</p>
<h2 id="1022024">1/02/2024 </h2>
<p>Sweet&#33; I was able to address Nikita&#39;s refactoring comments without too much hassle.</p>
<p>I guess the next task is to add it to the Verifier.</p>
<p>-&gt; I read the <code>llvm/lib/IR/Verifier.cpp</code> header and grep&#39;d for <code>smin</code>. Seems I can add a </p>
<pre><code class="language-julia">Intrinsics::vector_reduce_sthreecmp:
Intrinsics::vector_reduce_uthreecmp:</code></pre>
<p>on line 5378 and get away with this. I don&#39;t see other places where it&#39;s defined.</p>
<p>I think I&#39;ve hit my potential here. I will go do some tutorials.</p>
<h2 id="29022024">29/02/2024 </h2>
<h3 id="hazlo_cobarde">&quot;hazlo cobarde&quot;</h3>
<p>Add the <a href="https://discourse.llvm.org/t/llvm-add-3-way-comparison-intrinsics/76807/10">3 way comparison instruction</a> <code>&lt;&#61;&gt;</code> to LLVM. </p>
<p>I like this GSoC in particular because</p>
<ul>
<li><p>I will learn a wide swath of LLVM </p>
</li>
<li><p>I&#39;ll be working with a lot of optimization passes</p>
</li>
<li><p>I&#39;ll get to bring cool perf to C&#43;&#43;/Rust and Julia</p>
</li>
<li><p>I was dared by <a href="https://twitter.com/DrawsMiguel/status/1759708211286835309">the other, more talented Miguel</a> to actually help improve LLVM</p>
</li>
</ul>
<h3 id="task_1_add_to_langref">Task 1: Add to LangRef</h3>
<p><a href="https://llvm.org/docs/ExtendingLLVM.html">Add a new intrinsic</a> - <code>Langref</code>, then <code>Intrinsics.td</code>, then maybe the pass verifier.</p>
<p>I&#39;ve already put up a <a href="https://github.com/llvm/llvm-project/pull/83227">sample PR</a> and got redirected on what looks like the proper working path for this endeavour.</p>
<p>Oh neat, I&#39;ve finished. Only took about 1 hour with careful copy pasting. I&#39;m probably blundering the return type being <code>iM</code> bits, but someone will correct me.</p>
<p>Now, I need to add an entry of the intrinsic into TableGen.</p>
<h3 id="task_2_add_to_intrinsicstd">Task 2: Add to Intrinsics.td</h3>
<p>Whelp, I guess I gotta learn tablegen and then this <code>Intrinsics.td</code> file.</p>
<p>Ok, I found <a href="https://llvm.org/docs/TableGen/index.html">a non-intimidating TableGen overview</a>.</p>
<p>Gotta find the optimization wizardry in there after reading for a few minutes.</p>
<p>Alright, took more than a bit of an hour but <a href="https://github.com/llvm/llvm-project/pull/83227#issuecomment-1972375003">I got pushed something for this task</a>.</p>
<p>Pinged Nikita to get some adults to look at my horrible TableGen incantation.</p>
<p>See ya tomorrow.</p>
]]></content:encoded>
        
    <pubDate>Thu, 29 Feb 2024 00:00:00 +0000</pubDate>    
    
    
    <atom:author>
    <atom:name>Miguel Raz GuzmÃ¡n Macedo</atom:name>
    </atom:author>
                
</item>

<item>
    <title><![CDATA[From Julia to Rust]]></title>
    <link>https://miguelraz.github.io/blog/juliatorust/index.html</link>
    <guid>2</guid>
    <description><![CDATA[From Julia to Rust - learnings and reflections]]></description>    
    
    <content:encoded><![CDATA[<h3 id="from_julia_to_rust">From Julia to Rust ðº </h3>
<p>I&#39;ve been more serious about learning Rust recently, after dragging on with passive learning for a while. My first real programming language was Julia, and I know other Julians interested in Rust. I&#39;ve written this article for those people in mind, because Rust and Julia are good performance sparring partners, but Rust has a different mindset and tradeoffs that are worth considering.</p>
<p>I hope you enjoy it.</p>
<p><a href="https://www.youtube.com/watch?v&#61;drvAftwsTlU">TLDR:</a></p>
<blockquote>
<p>&quot;It is important to draw wisdom from many different places. If you take it from only one place, it becomes rigid and stale.&quot;</p>
<p>âUncle Iroh</p>
</blockquote>
<hr />
<h3 id="why_rust">Why Rust? ð¤· </h3>
<p>There are 3 talks that sold me on Rust being worth learning, the first is <a href="https://www.youtube.com/watch?v&#61;A3AdN7U24iU">by Carol Nichols</a> and the <a href="https://www.youtube.com/watch?v&#61;cUrggIAPJEs">second is a lecture by Ryan Eberhardt and Armin Nanavari</a>. The first talks about how about ~70&#37; of all bugs from the big tech corporations are from memory safety and that trains used to not have emergency brakes. The second explains how sytems programming codebases already impose the invariants of resource ownership on the coders - but that reasoning can be horribly error prone, tedious, and automated.</p>
<p>That&#39;s the point of technology&#33; To not have to worry about the previous generations problems because we figured out a way to offload that thinking to a machine. </p>
<p>The third talk that really sold me on Rust was <a href="https://www.usenix.org/conference/enigma2021/presentation/gaynor">Alex Gaynor&#39;s</a>. It&#39;s bad enough that a bank or a school web site could crash because of memory bugs, but once you take into account the fact that not even the best programmers in the world &#40;sorted by salaries, roughly&#41; can ship safe code, you start to despair a little. Then you hear about the incredibly battle-tested libraries like <a href="https://www.helpnetsecurity.com/2021/01/27/cve-2021-3156/">sudo </a> and, as the moral argument goes, you are likely going to put vulnerable people in harm&#39;s way if you keep shipping a broken tool. I buy the urgency of that argument more and more when journalists or human rights advocates get targeted by state actors due to a trivial &#40;but buried&#41; C mistake.</p>
<p>So that&#39;s the spiel for jumping on the Rust train when I argue with myself in the shower. What&#39;s the Rust&#39;s philosophy?</p>
<hr />
<h3 id="informal_introductions_-_tales_of_two_languages">Informal introductions - tales of two languages ð </h3>
<p>I will now give 2 hand-wavy historical rehashings of the origins of both languages.</p>
<p>You might know Julia&#39;s origin story - there were a gajillion DSLs for scientific computing, BLAS is a mess but implements polymorphism through namespacing for performance needs, and other libraries re-implemented a poor man&#39;s version of multiple dispatch because of the performance constraints. If you add a clever JIT to multiple dispatch capabilites, you can get ~C performance with ease if types can be inferred, and fortunately you can build a general programming language around that paradigm and those trade offs. Eventually, they baptized the language to honor the one true queen of <a href="https://youtu.be/lZb2JKhf-mk?t&#61;208">algorithms</a>.</p>
<p>Rust comes from a different place: Some years ago in Mozilla, Graydon Hoare and the team got fed up with systems programming and the C/C&#43;&#43; tool chain. They were working on a language that allowed for programmers to be productive in low-level systems, harness concurrency performance without the foot-bazookas, and avoid errors during run time. At first they had different systems for handling the previous problems, until the team pieced together that an ownership system, with a borrow checker at compile time, could kill 2 birds with one stone. Eventually, they named the language after the <a href="https://en.wikipedia.org/wiki/Rust_&#40;fungus&#41;">fungus</a>.</p>
<p>Recap: Julians were sick of unreusable code, niche DSLs and hacky polymorphism. With multiple dispatch as the central design feature they solved those problems. Rustaceans were sick of the C/C&#43;&#43; minefields and trying to keep all the invariants of large, error-prone codebases in their head. The idea of ownership and a borrow checker to know those errors <em>at compile time</em> and be data-race free is what&#39;s got them to where they are now.</p>
<p>There&#39;s obviously important details missing on both stories - you can get it from proper historians if you like, this is a brief and informal introduction. I will however, mention the other big Rustian idea of affine types when I talk about how they get a version of generic code we&#39;ve come to know and love in Julia land. Spoiler alert: you can get generic code if you pay the price of a Julia runtime, and that&#39;s not something Rustaceans want. If you want generics at compile time, you have to &quot;prove&quot; to the compiler that your types are constrained to some extent, and you relay that information by tacking on affine types to your code.</p>
<p>That&#39;s enough of an intro, here&#39;s the table of contents.</p>
<div class="franklin-toc"><ol><li>From Julia to Rust ðº </li><li>Why Rust? ð¤· </li><li>Informal introductions - tales of two languages ð </li><li>Handy learning materials ðð </li><li>What does generic Rustian code look like? ð </li><li>Rustian projects of interest ð¥ </li><li>Optimization walkthroughs ð </li><li>Papercuts and sharp edges â </li><li>Things I wish I&#39;d known earlier ð </li><li>Appreciation of Rust things ð¦  </li><li>What Rust can bring to Julia â </li><li>Acknowledgments ðð» </li></ol></div>
<hr />
<h3 id="handy_learning_materials">Handy learning materials ðð </h3>
<p>If for some reason you&#39;ve already decided that learning Rust is a worthy endeavour, here&#39;s my list of resources to learn. I think they are a good resource to follow in approximate order, but use whatever works, and if it doesn&#39;t, skip it.</p>
<ul>
<li><p><a href="https://www.rust-lang.org/">The Rust book</a>: Click the link to get started with installation and IDE setup. It pays to read it at least once cover to cover and not fret about coming back to the thorny bits.</p>
</li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName&#61;usernamehw.errorlens">VSCode Error Lens</a> and <a href="https://github.com/rust-analyzer/rust-analyzer">Rustanalyzer</a>: The quicker the feedback loop you get from the compiler, the sooner you can spot mistakes and keep going. These aren&#39;t mandatory but it&#39;s the easiest way to make the feedback loop faster.</p>
</li>
<li><p><a href="https://tourofrust.com/TOC_en.html">Tour of Rust</a>: Also has good examples.</p>
</li>
<li><p><a href="https://cheats.rs/">cheat.rs</a>: A cheat sheet for all the new syntax, priceless.</p>
</li>
<li><p><a href="https://doc.rust-lang.org/stable/rust-by-example/index.html">Rust by example</a>: Always good for a quick MWE.</p>
</li>
<li><p><a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html">Rust docs</a>: Their version of the Julia manual. Make sure to click the <code>&#91;&#43;&#93;</code> to see how the code drops down. I still spend time looking at the iterators page.</p>
</li>
<li><p>Courses and exercises:</p>
<ul>
<li><p><a href="https://exercism.io/my/tracks">Exercism</a>: If you want to get into some guided learning, Exercisms is great, but focuses too much on strings at the beginning for my liking. Make sure to look at the community solutions when you&#39;re done.</p>
</li>
<li><p><a href="https://fasterthanli.me/series/advent-of-code-2020/part-1">Advent of Code 2020 by Amos</a>: This was my first &quot;get your hands dirty&quot; with Rust experience. Other articles by Amos are great and friendly too, but this series was useful for figuring out a Rustian workflow and design thinking.</p>
</li>
<li><p><a href="https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html#lectures">Ryan Eberhardt Stanford course</a>: University course that gets you up and running with systems programming constraints and problem solving. I&#39;m not its target audience but it was great for understanding Rust&#39;s domain.</p>
</li>
<li><p><a href="https://github.com/jzarnett/ece459">Jeff Zarnett programming for performance course repo</a>, with a <a href="https://www.youtube.com/watch?v&#61;BE64OK7l20k&amp;list&#61;PLFCH6yhq9yAHnjKmB9RLA2Qdk3XhphqrN">full youtube playlist</a>: Another good course for stepping in directly into high performance computing - not done with it yet, but the professor is friendly and enthusiastic.</p>
</li>
<li><p><a href="https://github.com/rust-lang/rustlings">Rustlings</a>: I found some exercises too hard the first time I picked up the Rust book. Your Mileage May Vary but I did them solo and suffered. I would recommend pairing up with a buddy before attempting all of it.</p>
</li>
</ul>
</li>
<li><p><a href="https://rust-unofficial.github.io/too-many-lists/">Too many linked lists</a>: Another great walkthrough once you feel more comfortable reading and writing Rust.</p>
</li>
<li><p>Jon Gjengset&#39;s streams:  Jon Gjengset is a well-known Rust community member and has amazing quality streams - if you want to see a proficient Rustacean code, this is a good place to start.</p>
<ul>
<li><p><a href="https://www.youtube.com/watch?v&#61;h4RkCyJyXmM&amp;t&#61;2455s">sorting algos stream</a>: More friendly to beginners if you know your sorts.</p>
</li>
<li><p><a href="https://www.youtube.com/watch?v&#61;rMGWeSjctlY">multicore and atomics</a>: Gets into the weeds about all the pain that Rust can save you when you&#39;re implementing low-level tricky concurrency.</p>
</li>
</ul>
</li>
</ul>
<hr />
<p>Alright, so you&#39;re set up to go on a learning journey. What&#39;s Rust look like anyway when compared to Julia?</p>
<h3 id="what_does_generic_rustian_code_look_like">What does generic Rustian code look like? ð </h3>
<p>We love composability and multiple dispatch, so let&#39;s look at a short example of how to get the good ol&#39; Julia bang-for-buck, with a 1D point:</p>
<pre><code class="language-julia">import Base: &#43;
struct Point&#123;T&lt;:Real&#125;
    val::T
end&#43;&#40;x::Point&#123;T&#125;, y::Point&#123;T&#125;&#41; where T&lt;:Real &#61; Point&#123;T&#125;&#40;x.val &#43; y.val&#41;
a &#61; Point&#123;Int32&#125;&#40;1&#41;
b &#61; Point&#123;Int32&#125;&#40;2&#41;
a &#43; b # works
c &#61; Point&#123;Float32&#125;&#40;1.0&#41;
d &#61; Point&#123;Float32&#125;&#40;2.0&#41;
c &#43; d # Also works&#33;</code></pre>
<p>So, in Julia land, how do I get generic code? </p>
<p>I make sure to not use any explicit types and let the dispatch system do the rest. You use functions like <code>zero&#40;...&#41;</code>, <code>eltype&#40;...&#41;</code>. With the dispatches, I add them to the appropriate subtype with <code>where T&lt;:Foo</code>. If I define the appropriate methods, the others get composed atop of them , so I don&#39;t need to define <code>&#43;&#61;</code> once I&#39;ve defined <code>&#43;</code>. Duck type all the way - when something errors at runtime because I forgot a case &#40;like the fact there&#39;s no type promotion rules above&#41; I just write a function per call I missed and keep hacking on.</p>
<p>Setup a simple type hierarchy, define some functions on your types without using them explicitly, profit from not rewriting all the code, plug and chug as you run into errors or perf hits, look at docstrings in the REPL to help you out. Happy life.</p>
<p>Let&#39;s look at the rust example:</p>
<pre><code class="language-rust">use std::ops::Add;#&#91;derive&#40;Clone, Copy, Debug, PartialEq&#41;&#93;
struct Point&lt;T&gt; &#123;
    val: T
&#125;impl&lt;T: Add&lt;Output &#61; T&gt;&gt; Add for Point&lt;T&gt; &#123;
    type Output &#61; Self;
    
    fn add&#40;self, b: Self&#41; -&gt; Self::Output &#123;
        Self &#123; val: self.val &#43; b.val &#125;
    &#125;
&#125;fn main&#40;&#41; &#123;
    let a &#61; Point::&lt;i32&gt;&#123;val: 1&#125;;
    let b &#61; Point::&lt;i32&gt;&#123;val: 2&#125;;
    
    let c &#61; Point::&lt;f32&gt;&#123;val: 1.0&#125;;    println&#33;&#40;&quot;&#123;:?&#125;&quot;, a &#43; b&#41;;
    println&#33;&#40;&quot;&#123;:?&#125;&quot;, c &#61;&#61; c&#41;;
&#125;</code></pre>
<p>In Rust Land, how do I get a similar generic code?</p>
<p>I worked on like half of this code and then had to <a href="https://doc.rust-lang.org/std/ops/trait.Add.html">look it up</a>. You can run it in the <a href="https://play.rust-lang.org/?version&#61;stable&amp;mode&#61;debug&amp;edition&#61;2018&amp;gist&#61;e3dd98c60fa0cdebb5f1a582599d3b0d">Rust Playground here</a>. Avid readers will notice the following: </p>
<ol>
<li><p>Damn, that&#39;s a lot of boilerplate. ð£ </p>
</li>
<li><p>To get generics, you need a <code>struct</code> for your type, an <code>impl&lt;T&gt; &#36;TRAIT for Point&lt;T&gt;</code> block where the <code>add</code> function is defined, and type annotations like <code>Self::Output</code>, <code>Add&lt;Output &#61; T&gt;</code>.</p>
</li>
<li><p>There&#39;s a sort of &quot;name spacing&quot; with the turbo fish operator: <code>::&lt;this one&#33;&gt;</code>. We don&#39;t get functions that can share names but differ in behaviour. Bummer. &#40;We get this in Julia with some nicer outer constructors, but I think it takes from the thrust of the argument.&#41;</p>
</li>
<li><p>The <code>println&#33;</code> function is different - it&#39;s a macro, and it runs at parse time, also like Julia&#39;s macros. The chars inside the <code>&#123;:?&#125;</code> signal that we want debug printing, that we got above with the <code>#&#91;derive&#40;Debug&#41;&#93;</code>. Rust doesn&#39;t know how to print new structs if you don&#39;t define it, <a href="https://discourse.julialang.org/t/is-julias-way-of-oop-superior-to-c-python-why-julia-doesnt-use-class-based-oop/52058/84?u&#61;miguelraz">which, as Framespoints out, is one of the problems solved by multiple dispatch </a>.</p>
</li>
<li><p>Oh, those <code>#&#91;things&#40;above_the_struct&#41;&#93;</code> are also macros. I still don&#39;t know how they&#39;re different, but they seem to affect how the compiler interacts with the crate too. Since some traits &#40;like the ones for copying or printing&#41; are so boilerplate heavy and predictable, you can get some behaviour for &quot;free&quot; if you add the right <code>#&#91;derive&#40;...&#41;&#93;</code> stuff in the declaration. That&#39;s how the <code>c &#61;&#61; c</code> works actually, it&#39;s due to the <code>PartialEq</code>.</p>
</li>
</ol>
<p>The main workflow feels like this: </p>
<p>Slap a <code>&lt;T&gt;</code> in front of your struct and the fields you want it to be generic over. Look up the functions needed for each trait in the documentation. Setup a brief test case. Doesn&#39;t compile? See what <code>rustc</code> says and try and tack it on some traits; maybe you missed an affine type with <code>impl&lt;T: Foo&gt;</code> or the <code>Self::Output</code> - the compiler guides you through patching up your code. If you&#39;re asking for some generic behaviour, the compiler will complain and you&#39;ll have to add another trait implementation so that <em>it is damn sure</em> you&#39;re allowed to continue.</p>
<p>I also chose a particularly easy example: there&#39;s no associated data &#40;like a string&#41; in my <code>Point&lt;T&gt;</code>, so I don&#39;t need to prove to the compiler that my data doesn&#39;t outlive its uses - those are <code>lifetimes</code>, and they can get hairy, fast, but you&#39;ll run into them eventually. I also don&#39;t know how easily you could handle multiple generic types and the compile time penalties associated with them.</p>
<p>There&#39;s more syntax up front compared to Julia, and not just because we&#39;re writing library code here. Pythonistas can pick up Julia within a few hours and be productive. Rust has a lot more surface area to cover in learning the language: references, traits, impls, enums, lifetimes, pattern matching with <code>match</code>, macros, cargo flags for configuration, ownership and borrowing, Send and Sync...</p>
<p>Whodathunkit, Garbage Collectors let you worry about other things for a small runtime price. They might not be right for every use case but they&#39;re a solid investment.</p>
<hr />
<h3 id="rustian_projects_of_interest">Rustian projects of interest ð¥ </h3>
<p>There&#39;s a steep wall to climb when starting out with Rust - however, they&#39;ve nailed the user experience for learning tough stuff. I think it was Esteban Kuber who said something along the lines of &quot;We weren&#39;t missing a sufficiently smart compiler, but a more empathetic one&quot;.</p>
<p>Alright, so what&#39;s the view from the top look like? Like Julia, Rust is an incumbent in a crowded space, so how has it punched above it&#39;s weight against the established candidates? </p>
<p>Here&#39;s a list of all the projects that I&#39;ve found particularly of note to Julians.</p>
<ul>
<li><p><a href="https://github.com/rayon-rs/rayon">rayon</a> is the original reason I got interested in Rust. Check their <a href="https://github.com/rayon-rs/rayon#parallel-iterators-and-more">hello world</a> - the promise is that if you are using iterators, you can swap &#40;mostly&#41; <code>iter&#40;&#41;</code> for <code>par_iter&#40;&#41;</code> and at compile time you can know if your code will run in parallel. That&#39;s just about the friendliest user interface to parallelism besides <code>Threads.@threads</code>, and with some additional guarantees - a small update loop is easy to keep the invariants in your head, but it really pays when the Rust compiler catches a concurrency bug that spanned multiple files, modules and data structures. Cool tech note: Rayon uses the <a href="https://youtu.be/gof_OEv71Aw?t&#61;1184">same idea for work stealing thread scheduler</a> that Julia&#39;s parallel task run time system uses &#40;inspired by Cilk, get it? &#39;Cuz Rayon is a fake silk? Ha...&#41;. </p>
</li>
<li><p><a href="https://github.com/tokio-rs/tokio">tokio</a> deserves a mention as well for its capabilities for asynchronous programming, but I am not familiar enough with it to comment on it. Rust people get excited about it though&#33; </p>
</li>
</ul>
<p><em>NB</em>: It is non-trivial to compose <code>rayon</code> and <code>tokio</code> codes.</p>
<ul>
<li><p><a href="https://egraphs-good.github.io/">egg</a> and related projects like <a href="https://herbie.uwplse.org/">herbie</a>: A wicked fast egraph matching engine - a great competitor and inspiration for the Symbolics.jl ecosystem.</p>
</li>
<li><p><a href="https://github.com/mmtk/mmtk-core">MMtk and GCs</a>: Garbage Collectors are a family of algorithms that share behaviour, and different strategies can be built atop of tweakable parameters. The promise for building a configurable, performant and battle-tested back-end for Garbage Collectors is alive with this project by Steve Blackburn and gang. If you haven&#39;t heard of <a href="https://www.youtube.com/watch?v&#61;73djjTs4sew&amp;t&#61;914s">Immix</a> or <a href="https://github.com/RedlineResearch/floorplan">Floorplan</a>, enjoy the rabbithole. If you&#39;re new to GCs, <a href="https://www.cs.cornell.edu/courses/cs6120/2020fa/lesson/10/">this is a good starting point</a> for seasoned Julians.</p>
</li>
<li><p><a href="https://zaiste.net/posts/shell-commands-rust/">Rust CLI</a>: Rust people feel comfortable working in the terminal, and they&#39;ve taken that user experience Very Seriously and have a top notch performance and user experience for their command line CLIs. Here&#39;s a few of my favorites - you only need to <code>cargo install foo</code> and they should be properly installed on your system.</p>
<ul>
<li><p><a href="https://github.com/BurntSushi/ripgrep">rg</a>: SIMDified grep replacemnt tool &#40;for some use cases&#41;. Includes colors&#33;</p>
</li>
<li><p><a href="https://github.com/sharkdp/bat">bat</a>: cat clone with tons more built-in syntax highlighting.</p>
</li>
<li><p><a href="https://github.com/bootandy/dust">dust</a>: visualize disk space used by folders.</p>
</li>
<li><p><a href="https://lib.rs/crates/typeracer">typeracer</a>: fun typing game.</p>
</li>
<li><p><a href="https://lib.rs/crates/zoxide">taskwarrior-tui</a>: Todo tracker.</p>
</li>
<li><p><a href="https://lib.rs/crates/zoxide">zoxide</a>: directory autojumper. I don&#39;t really do <code>cd ../..</code> climbing around anymore I just do <code>z foo</code> a couple of times and that usually guesses right.</p>
</li>
<li><p><a href="https://github.com/zellij-org/zellij">zellij</a>: Terminal multiplexer with friendly UX. Young and promising.</p>
</li>
</ul>
</li>
<li><p><a href="https://github.com/plasma-umass/coz">coz</a>: Invaluable tool for <em>causal profiling</em>. <a href="https://youtu.be/r-TLSBdHe1A?t&#61;2182">Emery Berger&#39;s</a> presentation alone is worth knowing about this project. I reeeeeally want to nerdsnipe someone to port this to Julia.</p>
</li>
<li><p><a href="https://sled.rs/perf#e-prime-and-precise-language">sled&#39;s</a> approach to benchmarking and databases is top-notch. Also worthy of note is the same author&#39;s <code>rio</code> crate, which is a Rust interface for the <code>io_uring</code> linux kernel module, which can significantly speed up asynchronous programming. There&#39;s some WIP PRs for landing this for <code>libuv</code>, Julia&#39;s thread runtime backend, and that effort <a href="https://github.com/libuv/libuv/pull/2322">is close to wrapping up</a>.</p>
</li>
<li><p><a href="https://www.lpalmieri.com/posts/2019-02-23-scientific-computing-a-rust-adventure-part-0-vectors/">Scientific Computing in Rust</a>: A <em>must</em> to dive straight into linear algebra.</p>
</li>
<li><p><a href="https://www.lpalmieri.com/posts/2019-12-01-taking-ml-to-production-with-rust-a-25x-speedup/">Taking ML to production with Rust</a>: A sister article to the one above.</p>
</li>
<li><p><a href="https://github.com/ejmahler/RustFFT">Rust FFT</a>: They beat FFTW in some cases with this one, so it seems worthwhile to take a look ð .</p>
</li>
<li><p><a href="https://github.com/rusty-fast-solvers/rusty-green-kernel">Green function evaluation kernels</a>: Newer package, but I&#39;d like to see how special functions pan out in Rust land.</p>
</li>
<li><p><a href="https://docs.rs/polars/0.12.1/polars/">Polars</a>: A highly tuned dataframes implementation for some use cases. They&#39;ve topped the charts in some of the <a href="https://h2oai.github.io/db-benchmark/">H20ai benchmarks</a>, so they&#39;ve definitely got technical chops. &#40;They beat DataFrames.jl because of a sparsification trick which is a bit non-trivial to implement, but there&#39;s not necessarily an impediment to matching their speed.&#41;</p>
</li>
<li><p><a href="https://github.com/tokio-rs/loom">Loom</a>: a model checker for atomic primitives, sister project to <code>tokio</code>. I think Julia is a more natural fit for this approach given the ease of operator overloading  and it will be great to try something similar once Jameson&#39;s atomics PR lands.</p>
</li>
<li><p><a href="https://www.stateright.rs/">Stateright</a>: distributed systems model checker with a graphic user interface.</p>
</li>
<li><p><a href="https://github.com/xldenis/creusot">Creusot</a>: Add some macros to your Rust code, and have it formally verified by Why3.</p>
</li>
<li><p><a href="https://altsysrq.github.io/proptest-book/proptest/getting-started.html">proptest</a>: Configure strategies for exploring type instantiations to fuzz your tests, shrink the cases, and automatically track regressions. Impressive stuff&#33;</p>
</li>
<li><p><a href="https://gleam.run/">Gleam</a> and <a href="https://github.com/lumen/lumen">Lumen</a>: Gleam is a Rust backend for an Erlang based language and Lumen is a Rewritten-in-Rust implementation of the ErlangVM, BEAM. Erlang is a concurrency monster, and their actor based model is scalable as hell for certain workloads. I&#39;m glad to see Julia start to step into that domain with <a href="https://github.com/JuliaActors/Actors.jl">Actors.jl</a>. This seems to be the <em>right way</em> to abstract for fault tolerance workloads.</p>
</li>
</ul>
<p>There&#39;s oodles more. Check out <a href="https://www.crates.io">crates.io</a> or <a href="https://lib.rs">lib.rs</a> if you want to explore more &#40;this is their community based JuliaHub equivalent&#41;.</p>
<p>I&#39;ll make a special note of <a href="https://github.com/google/evcxr">evcxr</a>, a Rust REPL. For now, I don&#39;t think it&#39;s profitable to use Rust with a REPL-like workflow. I&#39;m too used to that in Julia, and that works well there, but I think there&#39;s a risk of digging yourself into a &quot;Everything must be a REPL&quot; mentality and cutting yourself off from learning opportunities. In Rust land, I don&#39;t mind doing as the Rustaceans do and learning to do things around a command line, navigating compiler errors and configuring flags and features for certain behaviours or deployment options. Since that&#39;s the package that I wanted to learn when I bought into Rust, I don&#39;t mind adapting into that mindset. I still wish them all the best and hope they can make the best possible Rust REPL - I&#39;d love to be wrong on this down the road.</p>
<hr />
<h3 id="optimization_walkthroughs">Optimization walkthroughs ð </h3>
<p>If you want to dive deep into nitty gritty performance fundamentals, these are the best guides I found for explaining the tradeoffs, gotchas, mental model, and engineering for those tasty, tasty flops.</p>
<ol>
<li><p><a href="http://www.frankmcsherry.org/assets/COST.pdf">COST paper</a>: Maybe doesn&#39;t fit here but this is one of my favorite papers and everyone should read it.</p>
</li>
<li><p><a href="https://parallel-rust-cpp.github.io/">Comparing parallel Rust and C&#43;&#43;</a></p>
</li>
<li><p><a href="https://deterministic.space/high-performance-rust.html">Cheap tricks</a></p>
</li>
<li><p><a href="https://nnethercote.github.io/perf-book/">The Rust performance Book</a></p>
</li>
<li><p><a href="https://likebike.com/posts/How_To_Write_Fast_Rust_Code.html">How to write Fast Rust code</a></p>
</li>
<li><p><a href="http://troubles.md/posts/rustfest-2018-workshop/">Fastware Workshope</a></p>
</li>
</ol>
<hr />
<h3 id="papercuts_and_sharp_edges">Papercuts and sharp edges â </h3>
<p>So Rust is &quot;worth learning&quot;, but these are roadblocks that I faced and would warn others about to save them some grief.</p>
<ul>
<li><p>You can learn another hobby waiting for Rust projects to compile. The price for compile-time guarantees/being the designated driver in the codebase is offloading more work to the compiler. They&#39;re working on leveraging concurrency for speeding up the pipeline, and it&#39;s gotten better. Let&#39;s just say they also suffer from TTFP ð .</p>
</li>
<li><p>Learn to run your code with <code>cargo run --release</code> <a href="https://deterministic.space/high-performance-rust.html">and other tricks</a>. This is the equivalent to running your Julia code with globals &#40;or <code>-O0</code> flags&#41;, and it&#39;s an easy gotcha. This will not change in Rust.</p>
</li>
<li><p>Rust people keep saying they have no Garbage Collector, *when they have a Region Based Garbage Collector**. It&#39;s all fun and games until they have to implement those linked lists...</p>
</li>
</ul>
<p>&#40;<em>NB</em>: After posting in <a href="https://news.ycombinator.com/item?id&#61;27407268">HackerNews</a>, Steve Klabnik has pointed out that the term <code>region based</code> is technical jargon in Programming Language Theory Literature as seen in section <a href="https://www.cs.umd.edu/projects/cyclone/papers/cyclone-regions.pdf">2 of this paper</a> on Cyclone&#39;s memory model.&#41; &#40;<em>NB2</em>: <code>kibwen</code> on HN pointed out that the term <code>garbage collection</code> implies dynamic memory management, whereas Rust&#39;s ownership system allows for lifetimes to be determined statically. In that sense, I&#39;m wrong except for when users opt-in to using <code>Rc</code>s and the like. Glad to be corrected&#33;&#41;</p>
<ul>
<li><p>Don&#39;t add crates manually&#33; Install <code>cargo-add</code>, use it to manage crate dependencies. That and some other tricks are great from doing the <code>AdventOfCode2020</code> from the article above.</p>
</li>
<li><p>For numerics, install <code>ndarray</code> and <code>num_traits</code>. Linear Algebra and numerics where not a primary focus of Rust when starting out as they where with Julia.</p>
</li>
<li><p>Benchmarking with <code>@btime</code> is painless, <code>criterion</code> is your best Rustian bet.</p>
</li>
<li><p>Setup your <code>rust-analyzer</code> and <code>error lens</code> plugins on VSCode or IDE asap, you&#39;ll thank me later. Rust-land expects you to be in constant dialogue with the compiler, and making that iteration cycle as ergonomic as possible will yield dividends in the long run. What we don&#39;t get from accessing help docs in the REPL, Rust people keep a terminal tab handy where they run <code>cargo watch -c</code> and get continuous feedback from the compiler.</p>
</li>
<li><p>You CAN&#39;T index into a String in Rust with ints&#33; <a href="https://doc.rust-lang.org/std/primitive.str.html#method.chars">Instead</a> use slices like <code>&amp;str&#91;1..&#93; &#61;&#61; str&#91;2:end&#93;</code> or iterators like <code>str.chars&#40;&#41;</code>, if I may riff on Rust and Julia syntax in the equality just there.</p>
</li>
<li><p>Reading from <code>stdin</code> is a pain as a newcomer. I wanted to try out some competitive coding exercises and reading from <code>stdin</code> was waaaay too rough for me at first. Eventually I cobbled this template up <a href="https://gist.github.com/miguelraz/d0341e9fee8c728baa99fd6fe86c1be1">link here</a> so that you don&#39;t struggle if you want to try a couple of CodeForces problems.</p>
</li>
<li><p>Not having a generic <code>rand</code> is just painful. So painful. This is my easiest workaround so far for generating a vector of <code>n</code> random entries:</p>
</li>
</ul>
<pre><code class="language-rust">let n &#61; 100;
use rand::distributions::Standard;
use rand::prelude::*;
thread_rng&#40;&#41;.sample_iter&#40;&amp;Standard&#41;.take&#40;n&#41;.collect&#40;&#41;</code></pre>
<p>&#40;Oh, and <code>rand</code> isn&#39;t part of the stdlib so that&#39;s another papercut&#41;.</p>
<blockquote>
<ul>
<li><p>There is no <code>@code_native</code> and friends in Rust - your best bet is to use the Rust Playground and click on the <code>...</code> to have it emit the total assembly. This only works for the top 100 most popular crates though. You can <code>cargo run --release -- --emit&#61;llvm-ir/asm</code> and then fish the results out of <code>target/</code>, but that&#39;s unwieldy - why does no one have a CLI for this yet?</p>
</li>
</ul>
</blockquote>
<p><em>NB</em>: <code>u/Schnatsel</code> has kindly pointed me towards <code>cargo-asm</code>. The interface is not as nice as <code>@code_XXX</code>, but I think I&#39;m satisfied with this. Thanks a ton&#33;</p>
<ul>
<li><p>Another multiple dispatch gripe: having to implement <code>Display</code> traits for new structs feels like pulling teeth, and this initial type signature seems inscrutable as a beginner:</p>
</li>
</ul>
<pre><code class="language-rust">use std::fmt;struct Point &#123;
    x: i32,
    y: i32,
&#125;impl fmt::Display for Point &#123;
    fn fmt&#40;&amp;self, f: &amp;mut fmt::Formatter&lt;&#39;_&gt;&#41; -&gt; fmt::Result &#123;
        write&#33;&#40;f, &quot;&#40;&#123;&#125;, &#123;&#125;&#41;&quot;, self.x, self.y&#41;
    &#125;
&#125;</code></pre>
<ul>
<li><p>Rust does NOT look like math and that hurts my little physicist heart. <a href="https://rust-lang.github.io/wg-async-foundations/vision/status_quo/niklaus_simulates_hydrodynamics.html">Look at this story of a hydrodynamics simulator code</a> vs anything in the DiffEq verse that is user facing or from ApproxFun.jl, or Turing.jl, or ... anything else. Even the linear algebra from <code>ndarray</code> is painful to understand unless you are comfortable in Rust, and all the <code>i as usize</code> conversions are a huge eye sore.</p>
</li>
<li><p>Many of your functions will be faster if you annotate them with <code>#&#91;inline&#93;</code>.</p>
</li>
</ul>
<hr />
<h3 id="things_i_wish_id_known_earlier">Things I wish I&#39;d known earlier ð </h3>
<p>These could have helped me settle down into a more productive workflow sooner. Get a buddy that knows Rust to see you code to figure most of these out.</p>
<ol>
<li><p>If you can, avoid the examples with Strings and &amp;str. Yes, they&#39;re a great motivation for systems people for all the gnarly use-after free and double-free and memory-leak examples - stick with numerical algorithms first, to get the gist of ownership, try and do some exercisms with iterators and Strings will be much easier to get after that. I don&#39;t think it&#39;s worth worrying about at first unless your target is systems.</p>
</li>
<li><p>The preferred way of &quot;whipping up an example in the REPL&quot;/getting a MWE is to <code>cargo new foo</code>, mucking about and then <code>cargo run --release</code> or using the Rust Playground.</p>
</li>
<li><p>If you&#39;re using an expansive test suite, <code>cargo test --test-threads 8</code> and <code>cargo test --quiet</code> are helpful flags.</p>
</li>
<li><p>For loops are not idiomatic in Rust - writing Fortran-ey code instead of iterators will lead to pain and slower loops. Spending time reading the examples in <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html">the iterator docs</a> and the community solutions in the exercisms will help a lot.</p>
</li>
<li><p>Just clone everything when you are starting out to get around most borrow checker shenanigans - worry about allocations later, Rust is usually fast enough.</p>
</li>
<li><p>In the following function, the types of <code>v</code> and <code>w</code> are a <code>slice</code> of <code>Int32</code>s, which are different from <code>Vec&lt;32&gt;</code>. Read the Scientific Computing link above to see a nice table of the differences. An array like <code>&#91;f32; 4&#93;</code> includes the size as part of the type, a slice like <code>&#91;f32&#93;</code> does not. Diving into linear algebra means being familiar with many <code>to_array&#40;&#41;</code>, <code>to_slice&#40;&#41;</code>, <code>from_array&#40;&#41;</code>, and <code>from_slice&#40;&#41;</code> cases.</p>
</li>
</ol>
<pre><code class="language-rust">fn dot&#40;v: &amp;&#91;i32&#93;, w: &amp;&#91;i32&#93;&#41; -&gt; i32 &#123;...&#125;</code></pre>
<ol start="6">
<li><p>Including docs and tests in the same file as your implementation is idiomatic - even the IDEs support clicking on the <code>#&#91;test&#93;</code> line and having that run. Julia has a nice workflow for test driven development out-of-the-box - Rust gives you some of those guarantees by... conversing with the compiler.</p>
</li>
<li><p>Rust has something similar to the concept of <code>type piracy</code>: they&#39;re called the <code>orphan rules</code>, as explained by <a href="https://blog.mgattozzi.dev/orphan-rules/">this Michael Gattozzi</a> post:</p>
</li>
</ol>
<blockquote>
<p>Recently at work I managed to hit the Orphan Rules implementing some things for an internal crate. Orphan Rules you say? These are ancient rules passed down from the before times &#40;pre 1.0&#41; that have to do with trait coherence. Mainly, if you and I both implement a trait from another crate on the same type in another crate and we compile the code, which implementation do we use?</p>
</blockquote>
<ol start="8">
<li><p>Rust is not as centralized with online communication as Julia is around Slack/Zulip/Discourse. Their version of <code>#appreciation</code> channels is to go on twitter and tell <code>@ekuber</code> what a joy the compilers errors are. There&#39;s tons of people on their Discord, and everywhere.</p>
</li>
</ol>
<hr />
<h3 id="appreciation_of_rust_things">Appreciation of Rust things ð¦  </h3>
<p>These are things the Rust people have nailed down.</p>
<ol>
<li><p>Ferris the crab is too cute.</p>
</li>
<li><p>Rust people take uwu-ification very, VERY seriously. <a href="https://github.com/Daniel-Liu-c0deb0t/uwu">The uwu</a> project uses SIMD to uwu-ify strings for <a href="https://twitter.com/twent_weznowor">great artistic value</a>. Julia and Rust both draw me because they make me feel more powerful when I code with them than I think I should be.</p>
</li>
<li><p>Governance: The Rust foundation and strong community conduct codes. Given the blow ups that have happened with open source communities recently from short-sighted governance or hate reactionaries tanking projects, this is a welcome sight that will probably pay off for decades to come.</p>
</li>
<li><p>Compiler error messages are second to none. Definitely check out <code>clippy</code> too and follow the hints. <code>cargo fmt</code> will also format all your crate so that Rust code is almost always a unified reading experience.</p>
</li>
<li><p><a href="https://rustbeginners.github.io/awesome-rust-mentors/">Awesome mentors</a>. This is a project maintained <code>Jane Lusby</code> and other volunteers. I&#39;ve gotten world-class mentorship from kind, patient and friendly Rust folks. Shoutout to <code>Jubilee</code> for her great wisdom and patience and the rest of the <code>stdsimd</code> gang.</p>
</li>
<li><p>They also poke the LLVM crowd to improve the compilation times, which is great.</p>
</li>
<li><p>They&#39;re doc deployment system is unified, polished, and friendly. Inline docs and tests are also great.</p>
</li>
<li><p><code>cargo</code> is a joy compared to <code>Make</code> hell. <code>Pkg</code> is somewhat inspired by it, so that rocks.</p>
</li>
</ol>
<hr />
<h3 id="what_rust_can_bring_to_julia">What Rust can bring to Julia â </h3>
<ol>
<li><p>A model of governance. The Rust community is at least 10x the size of Julia, and it&#39;s unclear that adding more hats to the same <code>TruckFactorCritical</code> people would help. That said, it&#39;d be better to have those conversations sooner rather than later, and building bridges with Rust people seems wise in the long term. I don&#39;t think that Rust is the closest model to look up to given the other projects under the NumFocus umbrella that we can learn from, but I don&#39;t see what is lost from learning from them.</p>
</li>
<li><p>Less vulnerable software in the world is a good thing. Oxidization is great&#33; Sometimes. I don&#39;t think any Julia internals will oxidize in the short term, but it would be an interesting experiment to say the least.</p>
</li>
<li><p><a href="https://www.youtube.com/watch?v&#61;rAF8mLI0naQ&amp;t&#61;947s">Error handling</a>: Multiple dispatch may prove advantageous in this domain, and it hasn&#39;t been as much of a priority as it has in Rust. Perhaps that merits some careful rethinking for future Julia versions.</p>
</li>
<li><p>Awesome Julia mentors, I think we need this.</p>
</li>
</ol>
<hr />
<h3 id="acknowledgments">Acknowledgments ðð» </h3>
<ul>
<li><p>Thanks to <code>Jubilee</code> for feedback on this post and the following corrections: </p>
<ul>
<li><p>Rust does not necessarily have an RC GC but a <a href="https://en.wikipedia.org/wiki/Region-based_memory_management">region based GC</a>. You can opt into the RC GC with <code>Arc</code> and <code>Rc</code> types.</p>
</li>
<li><p>Technically Rust doesn&#39;t have linear types but <a href="https://gankra.github.io/blah/linear-rust/">affine types</a>.</p>
</li>
<li><p>Tokio&#39;s story is not as simple as I had made it out to be so I cut some comments</p>
</li>
</ul>
</li>
<li><p><code>Alex Weech</code> helpfully suggested refactoring the original Julia Point code to be more similar to the Rust example.</p>
</li>
<li><p><code>Daniel MenÃ©ndez</code> helpfully suggested adding <code>crates.io</code> or <code>lib.rs</code></p>
</li>
<li><p>Thanks to <code>oliver</code> I also read about this post by Chris Lattner, author of LLVM, on the dangers of <a href="https://blog.llvm.org/2011/05/what-every-c-programmer-should-know_14.html">undefined behaviour</a>, to really scare you out of thinking you know what C is doing under the hood.</p>
</li>
<li><p><code>Zamalek1</code> on HN also provided useful feedback on precise academese: Rust is definitely a memory managed language, but that&#39;s been hoisted to compile time.</p>
</li>
<li><p>Thanks to <code>u/Schnatsel</code> for pointing me to a broken url here and to <code>cargo-asm</code>.</p>
</li>
<li><p>Thanks to <code>ministatsdev</code> for the string iterator nit.</p>
</li>
</ul>
]]></content:encoded>
        
    <pubDate>Sat, 05 Jun 2021 00:00:00 +0000</pubDate>    
    
    
    <atom:author>
    <atom:name>Miguel Raz GuzmÃ¡n Macedo</atom:name>
    </atom:author>
                
</item>
</channel></rss>